services:
  # NODO PRIMARIO (Servidor A)
  mongo1:
    image: mongo:7
    container_name: eventos-mongo1
    command: ["mongod", "--replSet", "rs0", "--bind_ip_all", "--port", "27017", "--quiet", "--logpath", "/dev/null"]
    ports:
      - "27017:27017"
    volumes:
      - mongo_data1:/data/db
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mongosh", "--quiet", "--eval", "quit(db.runCommand({ ping: 1 }).ok ? 0 : 2)"]
      interval: 5s
      timeout: 2s
      retries: 5

  # NODO SECUNDARIO (Servidor B)
  mongo2:
    image: mongo:7
    container_name: eventos-mongo2
    command: ["mongod", "--replSet", "rs0", "--bind_ip_all", "--quiet", "--logpath", "/dev/null"]
    ports:
      - "27018:27017"
    volumes:
      - mongo_data2:/data/db
    depends_on: [mongo1]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mongosh","--quiet", "--eval", "quit(db.runCommand({ ping: 1 }).ok ? 0 : 2)"]
      interval: 5s
      timeout: 2s
      retries: 5

  # NODO SECUNDARIO (Servidor C)
  mongo3:
    image: mongo:7
    container_name: eventos-mongo3
    command: ["mongod", "--replSet", "rs0", "--bind_ip_all", "--quiet", "--logpath", "/dev/null"]
    ports:
      - "27019:27017"
    volumes:
      - mongo_data3:/data/db
    depends_on: [mongo1]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mongosh","--quiet", "--eval", "quit(db.runCommand({ ping: 1 }).ok ? 0 : 2)"]
      interval: 5s
      timeout: 2s
      retries: 5
  mongo-init-replica:
    image: mongo:7
    depends_on:
      - mongo1
      - mongo2
      - mongo3
    entrypoint:
      - bash
      - -c
      - |
        echo "Esperando que los nodos estén listos..."
        sleep 10

        echo "Intentando inicializar replica set..."
        mongosh --host mongo1:27017 --quiet --eval '
          try {
            rs.initiate({
              _id: "rs0",
              members: [
                { _id: 0, host: "mongo1:27017" },
                { _id: 1, host: "mongo2:27017" },
                { _id: 2, host: "mongo3:27017" }
              ]
            })
          } catch (e) {
            if (e.codeName === "AlreadyInitialized") {
            print("Replica set ya estaba inicializado, continuando...")
          } else {
            throw e
            }
          }
        '

        echo "Esperando que el PRIMARY esté disponible..."
        until mongosh --host mongo1:27017 --quiet --eval '
        const status = rs.status();
        const primary = status.members.find(m => m.stateStr === "PRIMARY");
        print(primary ? "true" : "false");
        ' | grep true > /dev/null; do
        echo "Esperando PRIMARY..."
        sleep 2
        done

        echo "Replica set inicializado correctamente."
    restart: "no"

  # INTERFAZ WEB
  interfazweb:
    build:
      context: ./InterfazWeb
      dockerfile: Dockerfile
    ports:
      - "3000:80"

  # SERVIDOR
  server:
    build:
      context: .
      dockerfile: Servidor/Dockerfile
    ports:
      - "8080:8080"
    depends_on:
      - mongo1
      - mongo2
      - mongo3
      - mongo-init-replica
    environment:
      SPRING_DATA_MONGODB_URI: mongodb://mongo1:27017,mongo2:27017,mongo3:27017/eventos?replicaSet=rs0
      EVENTOS_SERVER_SECRET_KEY: ${EVENTOS_SERVER_SECRET_KEY}
      # Variables de OpenTelemetry
      OTEL_SERVICE_NAME: servidor
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
      OTEL_EXPORTER_OTLP_PROTOCOL: grpc
      OTEL_TRACES_EXPORTER: otlp
      OTEL_METRICS_EXPORTER: none
      OTEL_LOGS_EXPORTER: none

  # OpenTelemetry Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.139.0
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
    depends_on:
      - jaeger


  jaeger:
    image: jaegertracing/all-in-one:1.74.0
    ports:
      - "16686:16686"  # UI de Jaeger
      - "4317"         # Puerto para OTLP gRPC (collector)
    environment:
      LOG_LEVEL: error
      SPAN_STORAGE_TYPE: badger
      BADGER_DIRECTORY: /jaeger-data
      BADGER_SPAN_STORE_TTL: 72h
      BADGER_MAINTENANCE_INTERVAL: 1h

    volumes:
      - jaeger-data:/jaeger-data



  # TELEGRAM BOT
  telegrambot:
    build:
      context: .
      dockerfile: TelegramBot/Dockerfile
    depends_on:
      - server
    environment:
      EVENTOS_TELEGRAM_BOT_TOKEN: ${EVENTOS_TELEGRAM_BOT_TOKEN}
      EVENTOS_TELEGRAM_BOT_USERNAME: ${EVENTOS_TELEGRAM_BOT_USERNAME}

  redis-telegram:
    image: redis:8.2.3
    container_name: redis-telegram-eventos
    volumes:
      - redis_data:/data
    restart: unless-stopped
    command: [
      "redis-server",
      "--appendonly", "yes",
      "--appendfsync", "everysec",
      "--auto-aof-rewrite-percentage", "100",
      "--auto-aof-rewrite-min-size", "64mb",
      "--maxmemory", "200mb",
      "--maxmemory-policy", "allkeys-lru",
      "--dir", "/data",
      "--loglevel", "notice"
    ]

  prometheus:
    image: prom/prometheus:v3.7.3
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--storage.tsdb.retention.time=1d'
      - '--web.enable-lifecycle'
      - '--log.level=error'
    deploy:
      resources:
        limits:
          memory: 512M

  grafana:
    image: grafana/grafana:12.3.0-19020365962
    container_name: grafana
    ports:
      - "3002:3000"
    volumes:
      - grafana-data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_LOG_LEVEL=error
      - GF_LOG_CONSOLE_LEVEL=error
    deploy:
      resources:
        limits:
          memory: 256M


volumes:
  mongo_data1:
  mongo_data2:
  mongo_data3:
  redis_data:
  jaeger-data:
  prometheus-data:
  grafana-data: